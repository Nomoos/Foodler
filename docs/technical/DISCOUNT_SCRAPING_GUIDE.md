# Scrapov√°n√≠ a ukl√°d√°n√≠ slev z Kupi.cz

Tento dokument popisuje novou funkcionalitu pro stahov√°n√≠ a ukl√°d√°n√≠ kompletn√≠ch seznam≈Ø slev ze v≈°ech obchod≈Ø na kupi.cz vƒçetnƒõ dat platnosti.

## P≈ôehled nov√© funkcionality

### üéØ Co bylo p≈ôid√°no

1. **Extrakce dat platnosti** - `_parse_czech_date()` a `_extract_dates_from_element()`
   - Parsov√°n√≠ ƒçesk√Ωch datov√Ωch form√°t≈Ø (dd.mm.yyyy)
   - Automatick√° detekce rozsahu platnosti ("od ... do ...")
   - Podpora r≈Øzn√Ωch form√°t≈Ø z√°pisu data

2. **Stahov√°n√≠ slev ze v≈°ech obchod≈Ø** - `scrape_all_shop_discounts()`
   - Automatick√© projit√≠ v≈°ech dostupn√Ωch obchod≈Ø
   - Rate limiting (2 sekundy mezi po≈æadavky)
   - Robustn√≠ error handling

3. **Ukl√°d√°n√≠ do JSON** - `save_discounts_to_json()`
   - Strukturovan√© ukl√°d√°n√≠ s metadaty
   - ISO form√°t pro data
   - Zachov√°n√≠ v≈°ech informac√≠ o produktu

4. **Naƒç√≠t√°n√≠ z JSON** - `load_discounts_from_json()`
   - Zpƒõtn√° konverze do Product objekt≈Ø
   - Automatick√° deserializace dat
   - Round-trip kompatibilita

## Pou≈æit√≠

### 1. Z√°kladn√≠ pou≈æit√≠ - sta≈æen√≠ a ulo≈æen√≠ v≈°ech slev

```python
from src.scrapers.kupi_scraper import KupiCzScraper

# Inicializace scraperu
with KupiCzScraper() as scraper:
    # St√°hnout slevy ze v≈°ech obchod≈Ø
    all_discounts = scraper.scrape_all_shop_discounts()
    
    # Ulo≈æit do JSON souboru
    filepath = scraper.save_discounts_to_json(all_discounts)
    print(f"Ulo≈æeno do: {filepath}")
```

### 2. Pou≈æit√≠ p≈ôipraven√©ho skriptu

```bash
python scrape_and_save_discounts.py
```

Tento skript:
- St√°hne slevy ze v≈°ech obchod≈Ø (Lidl, Kaufland, Albert, Penny, Billa, Tesco, Globus, Makro)
- Zobraz√≠ statistiky (poƒçet produkt≈Ø z ka≈æd√©ho obchodu)
- Uk√°≈æe p≈ô√≠klady produkt≈Ø s datumy platnosti
- Ulo≈æ√≠ v≈°e do JSON souboru ve slo≈æce `data/`

### 3. Naƒçten√≠ ulo≈æen√Ωch dat

```python
from src.scrapers.kupi_scraper import KupiCzScraper

with KupiCzScraper() as scraper:
    # Naƒç√≠st data z JSON souboru
    discounts = scraper.load_discounts_from_json('data/kupi_discounts_20260118_103000.json')
    
    # Zpracovat produkty
    for store_id, products in discounts.items():
        print(f"\n{store_id.upper()}:")
        for product in products:
            print(f"  - {product.name}: {product.discount_price} Kƒç")
            if product.valid_until:
                print(f"    Plat√≠ do: {product.valid_until.strftime('%d.%m.%Y')}")
```

### 4. Filtrace produkt≈Ø podle data platnosti

```python
from datetime import datetime

# Naj√≠t produkty platn√© dnes
today = datetime.now()

active_deals = []
for store_id, products in discounts.items():
    for product in products:
        # Kontrola platnosti
        is_valid = True
        
        if product.valid_from and product.valid_from > today:
            is_valid = False  # Je≈°tƒõ nezaƒçalo
        
        if product.valid_until and product.valid_until < today:
            is_valid = False  # Ji≈æ skonƒçilo
        
        if is_valid:
            active_deals.append(product)

print(f"Nalezeno {len(active_deals)} aktivn√≠ch slev")
```

## Struktura JSON souboru

```json
{
  "scraped_at": "2026-01-18T10:30:00",
  "total_stores": 8,
  "total_products": 1234,
  "stores": {
    "lidl": {
      "product_count": 150,
      "products": [
        {
          "name": "Ku≈ôec√≠ prsa",
          "original_price": 150.0,
          "discount_price": 99.9,
          "discount_percentage": 33.4,
          "store": "Lidl",
          "valid_from": "2026-01-15T00:00:00",
          "valid_until": "2026-01-21T00:00:00",
          "image_url": "https://www.kupi.cz/...",
          "product_url": "https://www.kupi.cz/...",
          "category": null
        }
      ]
    }
  }
}
```

### V√Ωznam pol√≠:

- **scraped_at**: Kdy byla data sta≈æena
- **total_stores**: Poƒçet obchod≈Ø
- **total_products**: Celkov√Ω poƒçet produkt≈Ø
- **stores**: Slovn√≠k s daty podle obchod≈Ø
  - **product_count**: Poƒçet produkt≈Ø v obchodƒõ
  - **products**: Seznam produkt≈Ø
    - **valid_from**: Zaƒç√°tek platnosti akce (ISO form√°t)
    - **valid_until**: Konec platnosti akce (ISO form√°t)

## API Reference

### `scrape_all_shop_discounts() -> Dict[str, List[Product]]`

St√°hne slevy ze v≈°ech dostupn√Ωch obchod≈Ø.

**Returns:**
- Slovn√≠k kde kl√≠ƒç je ID obchodu (`'lidl'`, `'kaufland'`, ...) a hodnota je seznam `Product` objekt≈Ø

**P≈ô√≠klad:**
```python
all_discounts = scraper.scrape_all_shop_discounts()
# V√Ωsledek: {'lidl': [Product(...), ...], 'kaufland': [...], ...}
```

### `save_discounts_to_json(discounts, filename=None, directory='data') -> str`

Ulo≈æ√≠ slevy do JSON souboru.

**Parametry:**
- `discounts`: Slovn√≠k s produkty (v√Ωstup z `scrape_all_shop_discounts()`)
- `filename`: N√°zev souboru (v√Ωchoz√≠: `kupi_discounts_{timestamp}.json`)
- `directory`: C√≠lov√Ω adres√°≈ô (v√Ωchoz√≠: `'data'`)

**Returns:**
- Pln√° cesta k ulo≈æen√©mu souboru

**P≈ô√≠klad:**
```python
filepath = scraper.save_discounts_to_json(
    discounts, 
    filename='slevy_leden.json',
    directory='archive'
)
```

### `load_discounts_from_json(filepath) -> Dict[str, List[Product]]`

Naƒçte slevy z JSON souboru.

**Parametry:**
- `filepath`: Cesta k JSON souboru

**Returns:**
- Slovn√≠k s produkty ve stejn√©m form√°tu jako `scrape_all_shop_discounts()`

**P≈ô√≠klad:**
```python
discounts = scraper.load_discounts_from_json('data/kupi_discounts_20260118.json')
```

### `_parse_czech_date(date_text: str) -> Optional[datetime]`

Parsuje ƒçesk√© datum.

**Podporovan√© form√°ty:**
- `"15.1.2026"`
- `"15. 1. 2026"`
- `"15.1.26"`

**P≈ô√≠klad:**
```python
date = scraper._parse_czech_date("15.1.2026")
# Vrac√≠: datetime(2026, 1, 15, 0, 0)
```

### `_extract_dates_from_element(element) -> tuple[Optional[datetime], Optional[datetime]]`

Extrahuje data platnosti z HTML elementu.

**Detekuje vzory:**
- `"od 15.1.2026 do 21.1.2026"`
- `"Platnost: 15.1.2026 - 21.1.2026"`
- `"15.1.2026 - 21.1.2026"`
- `"od 15.1.2026"`
- `"plat√≠ do 21.1.2026"`

**Returns:**
- Tuple `(valid_from, valid_until)` nebo `(None, None)`

## Testov√°n√≠

Projekt obsahuje kompletn√≠ testovac√≠ sadu:

```bash
# Test nov√© funkcionality
python test_discount_scraping.py

# Test p≈Øvodn√≠ funkcionality (zaji≈°tƒõn√≠ zpƒõtn√© kompatibility)
python test_kupi_scraper.py
```

### Testovan√© oblasti:

1. **Parsov√°n√≠ dat** - r≈Øzn√© form√°ty ƒçesk√Ωch dat
2. **Extrakce dat z HTML** - rozsahy, jednotliv√° data
3. **Scrapov√°n√≠ ze v≈°ech obchod≈Ø** - mock testy
4. **JSON serializace/deserializace** - round-trip testy
5. **Zpƒõtn√° kompatibilita** - p≈Øvodn√≠ testy st√°le funguj√≠

## P≈ô√≠klady pou≈æit√≠

### Weekly meal planning s aktu√°ln√≠mi slevami

```python
from src.scrapers.kupi_scraper import KupiCzScraper
from datetime import datetime, timedelta

def find_this_week_deals():
    """Najde slevy platn√© tento t√Ωden."""
    
    with KupiCzScraper() as scraper:
        # St√°hnout v≈°echny slevy
        all_discounts = scraper.scrape_all_shop_discounts()
        
        # Ulo≈æit pro pozdƒõj≈°√≠ pou≈æit√≠
        filepath = scraper.save_discounts_to_json(all_discounts)
        
        # Filtrovat platn√© tento t√Ωden
        today = datetime.now()
        week_end = today + timedelta(days=7)
        
        weekly_deals = {}
        for store_id, products in all_discounts.items():
            valid_products = []
            
            for product in products:
                # Produkt je platn√Ω pokud:
                # - nem√° valid_from NEBO valid_from <= dnes
                # - nem√° valid_until NEBO valid_until >= konec t√Ωdne
                
                if product.valid_from and product.valid_from > today:
                    continue  # Je≈°tƒõ nezaƒçalo
                
                if product.valid_until and product.valid_until < today:
                    continue  # U≈æ skonƒçilo
                
                valid_products.append(product)
            
            if valid_products:
                weekly_deals[store_id] = valid_products
        
        return weekly_deals, filepath

# Pou≈æit√≠
deals, filepath = find_this_week_deals()
print(f"Nalezeno {sum(len(p) for p in deals.values())} slev platn√Ωch tento t√Ωden")
print(f"Data ulo≈æena v: {filepath}")
```

### Srovn√°n√≠ cen mezi obchody

```python
def compare_prices_across_stores(product_name_pattern, discounts):
    """Porovn√° ceny produktu nap≈ô√≠ƒç obchody."""
    
    results = []
    
    for store_id, products in discounts.items():
        for product in products:
            if product_name_pattern.lower() in product.name.lower():
                results.append({
                    'store': product.store,
                    'name': product.name,
                    'price': product.discount_price,
                    'discount': product.discount_percentage,
                    'valid_until': product.valid_until
                })
    
    # Se≈ôadit podle ceny
    results.sort(key=lambda x: x['price'])
    
    return results

# Pou≈æit√≠
with KupiCzScraper() as scraper:
    discounts = scraper.load_discounts_from_json('data/kupi_discounts_latest.json')
    
    # Naj√≠t nejlevnƒõj≈°√≠ ku≈ôec√≠ prsa
    chicken_prices = compare_prices_across_stores("ku≈ôec√≠ prsa", discounts)
    
    if chicken_prices:
        best = chicken_prices[0]
        print(f"Nejlevnƒõj≈°√≠: {best['name']}")
        print(f"Cena: {best['price']} Kƒç v {best['store']}")
        print(f"Sleva: {best['discount']}%")
        if best['valid_until']:
            print(f"Plat√≠ do: {best['valid_until'].strftime('%d.%m.%Y')}")
```

### Sledov√°n√≠ historie cen

```python
import os
import json
from datetime import datetime

def track_price_history(data_directory='data'):
    """Analyzuje historii cen z ulo≈æen√Ωch JSON soubor≈Ø."""
    
    price_history = {}
    
    # Naƒç√≠st v≈°echny JSON soubory
    for filename in sorted(os.listdir(data_directory)):
        if not filename.startswith('kupi_discounts_') or not filename.endswith('.json'):
            continue
        
        filepath = os.path.join(data_directory, filename)
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scraped_at = datetime.fromisoformat(data['scraped_at'])
        
        # Proj√≠t produkty
        for store_id, store_data in data['stores'].items():
            for product in store_data['products']:
                key = (product['name'], store_id)
                
                if key not in price_history:
                    price_history[key] = []
                
                price_history[key].append({
                    'date': scraped_at,
                    'price': product['discount_price'],
                    'discount': product.get('discount_percentage')
                })
    
    return price_history

# Pou≈æit√≠
history = track_price_history()

# Naj√≠t produkt s nejvƒõt≈°√≠ zmƒõnou ceny
for (name, store), prices in history.items():
    if len(prices) >= 2:
        prices.sort(key=lambda x: x['date'])
        first_price = prices[0]['price']
        last_price = prices[-1]['price']
        change = ((last_price - first_price) / first_price) * 100
        
        if abs(change) > 10:  # Zmƒõna > 10%
            print(f"{name} ({store}): {change:+.1f}%")
```

## Best Practices

### 1. Rate Limiting
```python
# Funkce scrape_all_shop_discounts() automaticky p≈ôid√°v√° 2s zpo≈ædƒõn√≠ mezi obchody
# Pro ruƒçn√≠ pou≈æit√≠:
import time

for store in stores:
    products = scraper.get_current_discounts(store=store['id'])
    time.sleep(2)  # 2 sekundy mezi po≈æadavky
```

### 2. Error Handling
```python
try:
    all_discounts = scraper.scrape_all_shop_discounts()
    filepath = scraper.save_discounts_to_json(all_discounts)
except Exception as e:
    logger.error(f"Chyba p≈ôi scrapov√°n√≠: {e}")
    # Fallback: pou≈æ√≠t star≈°√≠ data
    discounts = scraper.load_discounts_from_json('data/backup.json')
```

### 3. Automatick√© stahov√°n√≠
```python
import schedule

def scrape_and_save():
    """Automaticky stahovat slevy ka≈æd√Ω den v 6:00."""
    with KupiCzScraper() as scraper:
        discounts = scraper.scrape_all_shop_discounts()
        scraper.save_discounts_to_json(discounts)
        print(f"Slevy aktualizov√°ny: {datetime.now()}")

# Napl√°novat denn√≠ spu≈°tƒõn√≠
schedule.every().day.at("06:00").do(scrape_and_save)
```

## Zn√°m√© limitace

1. **Data platnosti** - Extrakce dat z√°vis√≠ na HTML struktu≈ôe kupi.cz
   - Pokud web zmƒõn√≠ strukturu, m≈Ø≈æe b√Ωt pot≈ôeba aktualizovat regex vzory
   - Ne v≈°echny produkty maj√≠ explicitnƒõ uveden√© datum platnosti

2. **Rate Limiting** - Respektujeme 2s prodlevu mezi po≈æadavky
   - Sta≈æen√≠ v≈°ech obchod≈Ø trv√° ~16 sekund (8 obchod≈Ø √ó 2s)

3. **Anti-scraping** - Kupi.cz m≈Ø≈æe blokovat nadmƒõrn√© po≈æadavky
   - Doporuƒçujeme stahovat maxim√°lnƒõ 1√ó dennƒõ
   - Pou≈æ√≠vejte cache (ulo≈æen√© JSON soubory)

## Migrace z p≈ôedchoz√≠ verze

Pokud jste pou≈æ√≠vali star≈°√≠ verzi scraperu:

```python
# STAR√Å verze
products = scraper.get_current_discounts(store='lidl')
# valid_from a valid_until byly v≈ædy None

# NOV√Å verze
products = scraper.get_current_discounts(store='lidl')
# valid_from a valid_until jsou nyn√≠ extrahov√°ny z HTML

# Plus nov√© funkce:
all_discounts = scraper.scrape_all_shop_discounts()
filepath = scraper.save_discounts_to_json(all_discounts)
```

Zpƒõtn√° kompatibilita je zachov√°na - existuj√≠c√≠ k√≥d bude fungovat beze zmƒõn.

## Podpora

Pokud naraz√≠te na probl√©my:

1. Zkontrolujte logy: `logging.basicConfig(level=logging.DEBUG)`
2. Ovƒõ≈ôte HTML strukturu kupi.cz pomoc√≠ browser DevTools
3. Spus≈•te testy: `python test_discount_scraping.py`
4. Otev≈ôete issue v repozit√°≈ôi

## Changelog

### v2.0.0 (2026-01-18)

‚ú® **Nov√© funkce:**
- Extrakce dat platnosti slev (`valid_from`, `valid_until`)
- Funkce pro sta≈æen√≠ slev ze v≈°ech obchod≈Ø
- JSON storage s metadaty
- Round-trip load/save funkcionalita

üß™ **Testy:**
- 10 nov√Ωch unit test≈Ø pro novou funkcionalitu
- Zachov√°na zpƒõtn√° kompatibilita (11 p≈Øvodn√≠ch test≈Ø)

üìö **Dokumentace:**
- Kompletn√≠ pr≈Øvodce pou≈æit√≠m
- P≈ô√≠klady pro bƒõ≈æn√© use case
- API reference

---

*Vytvo≈ôeno pro projekt Foodler - Family Diet Planning System*
